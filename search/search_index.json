{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"autodiff \u00b6 autodiff is a C++17 library that uses modern and advanced programming techniques to enable automatic computation of derivatives in an efficient and easy way. Attention autodiff is planned to be a long-term maintained automatic differentiation project, with many more algorithms being implemented in the future. Please have in mind, however, that autodiff is still in its earlier stages of development. We welcome you to use autodiff and recommend us any improvements you think it is necessary. Demonstration \u00b6 Consider the following function f(x, y, z) : double f ( double x , double y , double z ) { return ( x + y + z ) * exp ( x * y * z ); } which we use use to evaluate variable u = f(x, y, z) : double x = 1.0 ; double y = 2.0 ; double z = 3.0 ; double u = f ( x , y , z ); How can we minimally transform this code so that not only u , but also its derivatives \u2202u/\u2202x , \u2202u/\u2202y , and \u2202u/\u2202z , can be computed? The next two sections present how this can be achieved using two automatic differentiation algorithms implemented in autodiff : forward mode and reverse mode . Forward mode \u00b6 In a forward mode automatic differentiation algorithm, both output variables and one or more of their derivatives are computed together. For example, the function evaluation f(x, y, z) can be transformed in a way that it will not only produce the value of u , the output variable , but also one or more of its derivatives (\u2202u/\u2202x, \u2202u/\u2202y, \u2202u/\u2202z) with respect to the input variables (x, y, z) . Enabling forward automatic differentiation for the calculation of derivatives using autodiff is relatively simple. For our previous function f , we only need to replace the floating-point type double to autodiff::dual for both input and output variables: dual f ( dual x , dual y , dual z ) { return ( x + y + z ) * exp ( x * y * z ); } We can now compute the derivatives \u2202u/\u2202x , \u2202u/\u2202y , and \u2202u/\u2202z as follows: dual x = 1.0 ; dual y = 2.0 ; dual z = 3.0 ; dual u = f ( x , y , z ); double dudx = derivative ( f , wrt ( x ), x , y , z ); double dudy = derivative ( f , wrt ( y ), x , y , z ); double dudz = derivative ( f , wrt ( z ), x , y , z ); where the auxiliary function autodiff::wrt , which has the meaning of with respect to , is used to indicate which input variable (x, y, z) is the selected one to compute the partial derivative of f . Reverse mode \u00b6 In a reverse mode automatic differentiation algorithm, the output variable of a function is evaluated first. During this function evaluation, all mathematical operations between the input variables are \"recorded\" in an expression tree . By traversing this tree from top-level (output variable as the root node) to bottom-level (input variables as the leaf nodes), it is possible to compute the contribution of each branch on the derivatives of the output variable with respect to input variables. Thus, a single pass in a reverse mode calculation computes all derivatives , in contrast with forward mode, which requires one pass for each input variable. Note, however, that it is possible to change the behavior of a forward pass so that many (even all) derivatives of an output variable are computed simultaneously (e.g., in a single forward pass, \u2202u/\u2202x , \u2202u/\u2202y , and \u2202u/\u2202z are evaluated together with u , in contrast with three forward passes, each one computing the individual derivatives). Similar as before, we can use autodiff to enable reverse automatic differentiation for our function f by simply replacing type double by autodiff::var as follows: var f ( var x , var y , var z ) { return ( x + y + z ) * exp ( x * y * z ); } The code below demonstrates how the derivatives \u2202u/\u2202x , \u2202u/\u2202y , and \u2202u/\u2202z can be calculated: var x = 1.0 ; var y = 2.0 ; var z = 3.0 ; var u = f ( x , y , z ); Derivatives dud = derivatives ( u ); double dudx = dud ( x ); double dudy = dud ( y ); double dudz = dud ( z ); The function autodiff::derivatives will traverse the expression tree stored in variable u and compute all its derivatives with respect to the input variables (x, y, z) , which are then stored in the object dud . The derivative of u with respect to input variable x (i.e., \u2202u/\u2202x ) can then be extracted from dud using dud(x) . The operations dud(x) , dud(y) , dud(z) involve no computations! Just extraction of derivatives previously computed with a call to function autodiff::derivatives .","title":"Home"},{"location":"#autodiff","text":"autodiff is a C++17 library that uses modern and advanced programming techniques to enable automatic computation of derivatives in an efficient and easy way. Attention autodiff is planned to be a long-term maintained automatic differentiation project, with many more algorithms being implemented in the future. Please have in mind, however, that autodiff is still in its earlier stages of development. We welcome you to use autodiff and recommend us any improvements you think it is necessary.","title":"autodiff"},{"location":"#demonstration","text":"Consider the following function f(x, y, z) : double f ( double x , double y , double z ) { return ( x + y + z ) * exp ( x * y * z ); } which we use use to evaluate variable u = f(x, y, z) : double x = 1.0 ; double y = 2.0 ; double z = 3.0 ; double u = f ( x , y , z ); How can we minimally transform this code so that not only u , but also its derivatives \u2202u/\u2202x , \u2202u/\u2202y , and \u2202u/\u2202z , can be computed? The next two sections present how this can be achieved using two automatic differentiation algorithms implemented in autodiff : forward mode and reverse mode .","title":"Demonstration"},{"location":"#forward-mode","text":"In a forward mode automatic differentiation algorithm, both output variables and one or more of their derivatives are computed together. For example, the function evaluation f(x, y, z) can be transformed in a way that it will not only produce the value of u , the output variable , but also one or more of its derivatives (\u2202u/\u2202x, \u2202u/\u2202y, \u2202u/\u2202z) with respect to the input variables (x, y, z) . Enabling forward automatic differentiation for the calculation of derivatives using autodiff is relatively simple. For our previous function f , we only need to replace the floating-point type double to autodiff::dual for both input and output variables: dual f ( dual x , dual y , dual z ) { return ( x + y + z ) * exp ( x * y * z ); } We can now compute the derivatives \u2202u/\u2202x , \u2202u/\u2202y , and \u2202u/\u2202z as follows: dual x = 1.0 ; dual y = 2.0 ; dual z = 3.0 ; dual u = f ( x , y , z ); double dudx = derivative ( f , wrt ( x ), x , y , z ); double dudy = derivative ( f , wrt ( y ), x , y , z ); double dudz = derivative ( f , wrt ( z ), x , y , z ); where the auxiliary function autodiff::wrt , which has the meaning of with respect to , is used to indicate which input variable (x, y, z) is the selected one to compute the partial derivative of f .","title":"Forward mode"},{"location":"#reverse-mode","text":"In a reverse mode automatic differentiation algorithm, the output variable of a function is evaluated first. During this function evaluation, all mathematical operations between the input variables are \"recorded\" in an expression tree . By traversing this tree from top-level (output variable as the root node) to bottom-level (input variables as the leaf nodes), it is possible to compute the contribution of each branch on the derivatives of the output variable with respect to input variables. Thus, a single pass in a reverse mode calculation computes all derivatives , in contrast with forward mode, which requires one pass for each input variable. Note, however, that it is possible to change the behavior of a forward pass so that many (even all) derivatives of an output variable are computed simultaneously (e.g., in a single forward pass, \u2202u/\u2202x , \u2202u/\u2202y , and \u2202u/\u2202z are evaluated together with u , in contrast with three forward passes, each one computing the individual derivatives). Similar as before, we can use autodiff to enable reverse automatic differentiation for our function f by simply replacing type double by autodiff::var as follows: var f ( var x , var y , var z ) { return ( x + y + z ) * exp ( x * y * z ); } The code below demonstrates how the derivatives \u2202u/\u2202x , \u2202u/\u2202y , and \u2202u/\u2202z can be calculated: var x = 1.0 ; var y = 2.0 ; var z = 3.0 ; var u = f ( x , y , z ); Derivatives dud = derivatives ( u ); double dudx = dud ( x ); double dudy = dud ( y ); double dudz = dud ( z ); The function autodiff::derivatives will traverse the expression tree stored in variable u and compute all its derivatives with respect to the input variables (x, y, z) , which are then stored in the object dud . The derivative of u with respect to input variable x (i.e., \u2202u/\u2202x ) can then be extracted from dud using dud(x) . The operations dud(x) , dud(y) , dud(z) involve no computations! Just extraction of derivatives previously computed with a call to function autodiff::derivatives .","title":"Reverse mode"},{"location":"about/","text":"About \u00b6 Philosophy \u00b6 autodiff aims to be both efficient and easy to use C++ library for automatic differentiation. If you appreciate how it has been developed so far, and want to contribute, you are most welcome to join us in its development. And if you dislike it, please let us know how we can improve! You can contact us here . License \u00b6 MIT License Copyright \u00a9 2018\u20132019 Allan Leal Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"About"},{"location":"about/#about","text":"","title":"About"},{"location":"about/#philosophy","text":"autodiff aims to be both efficient and easy to use C++ library for automatic differentiation. If you appreciate how it has been developed so far, and want to contribute, you are most welcome to join us in its development. And if you dislike it, please let us know how we can improve! You can contact us here .","title":"Philosophy"},{"location":"about/#license","text":"MIT License Copyright \u00a9 2018\u20132019 Allan Leal Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"faq/","text":"Why should I consider automatic differentiation? \u00b6 The following are the reasons why you should consider automatic differentiation in your computational project: your functions are extremely complicated; manually implementing analytical derivatives is a tedious and error-prone task; and computing derivatives using finite differences can be inaccurate and inefficient. What is the difference between reverse and forward modes? \u00b6 Here is a brief, practical, and qualitative discussion on the differences between these two automatic differentiation algorithms. In a forward mode algorithm, each function evaluation produces not only its output value but also its derivative. The evaluation of a vector function, for example, computes both the output vector as well as the derivative of this vector, in general, with respect to one of the input variables (e.g., \u2202u/\u2202x , \u2202u/\u2202y ). However, the forward mode algorithm can also be used to compute directional derivatives. In this case, the derivative of the output vector with respect to a given direction vector is performed. We could say that, fundamentally, the forward mode always computes directional derivatives. The simplest case of a derivative with respect to a single input variable corresponds thus with a directional derivative whose direction vector is a unit vector along the input variable of interest (e.g., the unit vector along x , or along y , and so forth). In a reverse mode algorithm, each function evaluation produces a complete expression tree that contains the sequence of all mathematical operations between the input variables to produce the output variable (a scalar). Once this expression tree is constructed, it is then used to compute the derivatives of the scalar output variable with respect to all input variables. Is one algorithm always faster than another? \u00b6 Even though the reverse mode algorithm requires a single function evaluation and all derivatives are subsequently computed in a single pass, as the constructed expression tree is traversed, the forward algorithm can still be a much more efficient choice for your application , despite its multiple, repeated function evaluations, one for each input variable. This is because the implementation of the forward mode algorithm in autodiff uses template meta-programming techniques to avoid as much as possible temporary memory allocations and to optimize the calculations in certain cases. The reverse mode algorithm, on the other hand, requires the construction of an expression tree at runtime, and, for this, several dynamic memory allocations are needed, which can be costly. We plan to implement alternative versions of this algorithm, in which memory allocation could be done in advance to decrease the number of subsequent allocations. This, however, will require a slightly more complicated usage than it is already provided by the reverse mode algorithm implemented in autodiff . Which automatic differentiation algorithm should I use? \u00b6 Ideally, you should try both algorithms for your specific needs, benchmark them, and then make an informed decision about which one to use. If you're in a hurry, consider: forward mode : if you have a vector function, or a scalar function with not many input variables. reverse mode : if you have a scalar function with many (thousands or more) input variables. Have in mind this is a very simplistic rule, and you should definitely try both algorithms whenever possible, since the forward mode could still be faster than reverse mode even when many input variables are considered for a function of interest.","title":"FAQ"},{"location":"faq/#why-should-i-consider-automatic-differentiation","text":"The following are the reasons why you should consider automatic differentiation in your computational project: your functions are extremely complicated; manually implementing analytical derivatives is a tedious and error-prone task; and computing derivatives using finite differences can be inaccurate and inefficient.","title":"Why should I consider automatic differentiation?"},{"location":"faq/#what-is-the-difference-between-reverse-and-forward-modes","text":"Here is a brief, practical, and qualitative discussion on the differences between these two automatic differentiation algorithms. In a forward mode algorithm, each function evaluation produces not only its output value but also its derivative. The evaluation of a vector function, for example, computes both the output vector as well as the derivative of this vector, in general, with respect to one of the input variables (e.g., \u2202u/\u2202x , \u2202u/\u2202y ). However, the forward mode algorithm can also be used to compute directional derivatives. In this case, the derivative of the output vector with respect to a given direction vector is performed. We could say that, fundamentally, the forward mode always computes directional derivatives. The simplest case of a derivative with respect to a single input variable corresponds thus with a directional derivative whose direction vector is a unit vector along the input variable of interest (e.g., the unit vector along x , or along y , and so forth). In a reverse mode algorithm, each function evaluation produces a complete expression tree that contains the sequence of all mathematical operations between the input variables to produce the output variable (a scalar). Once this expression tree is constructed, it is then used to compute the derivatives of the scalar output variable with respect to all input variables.","title":"What is the difference between reverse and forward modes?"},{"location":"faq/#is-one-algorithm-always-faster-than-another","text":"Even though the reverse mode algorithm requires a single function evaluation and all derivatives are subsequently computed in a single pass, as the constructed expression tree is traversed, the forward algorithm can still be a much more efficient choice for your application , despite its multiple, repeated function evaluations, one for each input variable. This is because the implementation of the forward mode algorithm in autodiff uses template meta-programming techniques to avoid as much as possible temporary memory allocations and to optimize the calculations in certain cases. The reverse mode algorithm, on the other hand, requires the construction of an expression tree at runtime, and, for this, several dynamic memory allocations are needed, which can be costly. We plan to implement alternative versions of this algorithm, in which memory allocation could be done in advance to decrease the number of subsequent allocations. This, however, will require a slightly more complicated usage than it is already provided by the reverse mode algorithm implemented in autodiff .","title":"Is one algorithm always faster than another?"},{"location":"faq/#which-automatic-differentiation-algorithm-should-i-use","text":"Ideally, you should try both algorithms for your specific needs, benchmark them, and then make an informed decision about which one to use. If you're in a hurry, consider: forward mode : if you have a vector function, or a scalar function with not many input variables. reverse mode : if you have a scalar function with many (thousands or more) input variables. Have in mind this is a very simplistic rule, and you should definitely try both algorithms whenever possible, since the forward mode could still be faster than reverse mode even when many input variables are considered for a function of interest.","title":"Which automatic differentiation algorithm should I use?"},{"location":"installation/","text":"Installation \u00b6 Installing autodiff is easy, since it is a header-only library . Follow the steps below. Download \u00b6 Download autodiff by either git cloning its GitHub repository : git clone https://github.com/autodiff/autodiff or by clicking here to start the download of a zip file, which you should extract to a directory of your choice. Installation by copying \u00b6 Assuming the git cloned repository or extracted source code resides in a directory named autodiff , you can now copy the directory autodiff/autodiff to somewhere in your project directory and directly use autodiff . This quick and dirty solution might suffices in most cases. If this solution bothers you, read the next section! Installation using CMake \u00b6 If you have cmake installed in your system, you can then install autodiff (and also build its tests and examples) as follows: mkdir build && cd build cmake .. cmake --build . --target install Attention We assume above that you are in the root of the source code directory, under autodiff ! The build directory will be created at autodiff/build . The previous installation commands will require administrative rights in most systems. To install autodiff locally, use: cmake .. -DCMAKE_INSTALL_PREFIX=/some/local/dir Installation failed. What do I do? \u00b6 Create a new issue , and let us know what happened and possibly howe we can improve the installation process of autodiff .","title":"Installation"},{"location":"installation/#installation","text":"Installing autodiff is easy, since it is a header-only library . Follow the steps below.","title":"Installation"},{"location":"installation/#download","text":"Download autodiff by either git cloning its GitHub repository : git clone https://github.com/autodiff/autodiff or by clicking here to start the download of a zip file, which you should extract to a directory of your choice.","title":"Download"},{"location":"installation/#installation-by-copying","text":"Assuming the git cloned repository or extracted source code resides in a directory named autodiff , you can now copy the directory autodiff/autodiff to somewhere in your project directory and directly use autodiff . This quick and dirty solution might suffices in most cases. If this solution bothers you, read the next section!","title":"Installation by copying"},{"location":"installation/#installation-using-cmake","text":"If you have cmake installed in your system, you can then install autodiff (and also build its tests and examples) as follows: mkdir build && cd build cmake .. cmake --build . --target install Attention We assume above that you are in the root of the source code directory, under autodiff ! The build directory will be created at autodiff/build . The previous installation commands will require administrative rights in most systems. To install autodiff locally, use: cmake .. -DCMAKE_INSTALL_PREFIX=/some/local/dir","title":"Installation using CMake"},{"location":"installation/#installation-failed-what-do-i-do","text":"Create a new issue , and let us know what happened and possibly howe we can improve the installation process of autodiff .","title":"Installation failed. What do I do?"},{"location":"tutorials/","text":"Tutorials \u00b6 Forward mode \u00b6 Single-variable function \u00b6 // C++ includes #include <iostream> using namespace std ; // autodiff include #include <autodiff/forward.hpp> using namespace autodiff ; // The single-variable function for which derivatives are needed dual f ( dual x ) { return 1 + x + x * x + 1 / x + log ( x ); } int main () { dual x = 2.0 ; // the input variable x dual u = f ( x ); // the output variable u double dudx = derivative ( f , wrt ( x ), x ); // evaluate the derivative du/dx cout << \"u = \" << u << endl ; // print the evaluated output u cout << \"du/dx = \" << dudx << endl ; // print the evaluated derivative du/dx } Multi-variable function \u00b6 // C++ includes #include <iostream> using namespace std ; // autodiff include #include <autodiff/forward.hpp> using namespace autodiff ; // The multi-variable function for which derivatives are needed dual f ( dual x , dual y , dual z ) { return 1 + x + y + z + x * y + y * z + x * z + x * y * z + exp ( x / y + y / z ); } int main () { dual x = 1.0 ; // the input variable x dual y = 2.0 ; // the input variable y dual z = 3.0 ; // the input variable z dual u = f ( x , y , z ); // the output variable u double dudx = derivative ( f , wrt ( x ), x , y , z ); // evaluate the derivative du/dx double dudy = derivative ( f , wrt ( y ), x , y , z ); // evaluate the derivative du/dy double dudz = derivative ( f , wrt ( z ), x , y , z ); // evaluate the derivative du/dz cout << \"u = \" << u << endl ; // print the evaluated output u cout << \"du/dx = \" << dudx << endl ; // print the evaluated derivative du/dx cout << \"du/dy = \" << dudy << endl ; // print the evaluated derivative du/dy cout << \"du/dz = \" << dudz << endl ; // print the evaluated derivative du/dz } Multi-variable function with parameters \u00b6 // C++ includes #include <iostream> using namespace std ; // autodiff include #include <autodiff/forward.hpp> using namespace autodiff ; // A type defining parameters for a function of interest struct Params { dual a ; dual b ; dual c ; }; // The function that depends on parameters for which derivatives are needed dual f ( dual x , const Params & params ) { return params . a * sin ( x ) + params . b * cos ( x ) + params . c * sin ( x ) * cos ( x ); } int main () { Params params ; // initialize the parameter variables params . a = 1.0 ; // the parameter a of type dual, not double! params . b = 2.0 ; // the parameter b of type dual, not double! params . c = 3.0 ; // the parameter c of type dual, not double! dual x = 0.5 ; // the input variable x dual u = f ( x , params ); // the output variable u double dudx = derivative ( f , wrt ( x ), x , params ); // evaluate the derivative du/dx double duda = derivative ( f , wrt ( params . a ), x , params ); // evaluate the derivative du/da double dudb = derivative ( f , wrt ( params . b ), x , params ); // evaluate the derivative du/db double dudc = derivative ( f , wrt ( params . c ), x , params ); // evaluate the derivative du/dc cout << \"u = \" << u << endl ; // print the evaluated output u cout << \"du/dx = \" << dudx << endl ; // print the evaluated derivative du/dx cout << \"du/da = \" << duda << endl ; // print the evaluated derivative du/da cout << \"du/db = \" << dudb << endl ; // print the evaluated derivative du/db cout << \"du/dc = \" << dudc << endl ; // print the evaluated derivative du/dc } Gradient of a scalar function \u00b6 // C++ includes #include <iostream> using namespace std ; // Eigen includes #include <eigen3/Eigen/Core> using namespace Eigen ; // autodiff include #include <autodiff/forward.hpp> #include <autodiff/forward/eigen.hpp> using namespace autodiff ; // The scalar function for which the gradient is needed dual f ( const VectorXdual & x ) { return x . cwiseProduct ( x ). sum (); // sum([x(i) * x(i) for i = 1:5]) } int main () { VectorXdual x ( 5 ); // the input vector x with 5 variables x << 1 , 2 , 3 , 4 , 5 ; // x = [1, 2, 3, 4, 5] dual u = f ( x ); // the output variable u VectorXd dudx = gradient ( f , x ); // evaluate the gradient vector du/dx cout << \"u = \" << u << endl ; // print the evaluated output u cout << \"grad(u) = \\n \" << dudx << endl ; // print the evaluated gradient vector du/dx } Jacobian of a vector function \u00b6 // C++ includes #include <iostream> using namespace std ; // Eigen includes #include <eigen3/Eigen/Core> using namespace Eigen ; // autodiff include #include <autodiff/forward.hpp> #include <autodiff/forward/eigen.hpp> using namespace autodiff ; // The vector function for which the Jacobian is needed VectorXdual f ( const VectorXdual & x ) { return x * x . sum (); } int main () { VectorXdual x ( 5 ); // the input vector x with 5 variables x << 1 , 2 , 3 , 4 , 5 ; // x = [1, 2, 3, 4, 5] VectorXdual u = f ( x ); // the output vector u MatrixXd dudx = jacobian ( f , u , x ); // evaluate the Jacobian matrix du/dx cout << \"u = \\n \" << u << endl ; // print the evaluated output vector u cout << \"du/dx = \\n \" << dudx << endl ; // print the evaluated Jacobian matrix du/dx } Higher-order derivatives of a multi-variable function \u00b6 // C++ includes #include <iostream> using namespace std ; // autodiff include #include <autodiff/forward.hpp> using namespace autodiff ; // Define a 2nd order dual type using HigherOrderDual<N> construct. using dual2nd = HigherOrderDual < 2 > ; // The single-variable function for which derivatives are needed dual2nd f ( dual2nd x , dual2nd y ) { return 1 + x + y + x * y + y / x + log ( x / y ); } int main () { dual2nd x = 2.0 ; // the input variable x dual2nd y = 1.0 ; // the input variable y dual2nd u = f ( x , y ); // the output variable u dual ux = derivative ( f , wrt ( x ), x , y ); // evaluate the derivative du/dx dual uy = derivative ( f , wrt ( y ), x , y ); // evaluate the derivative du/dy double uxx = derivative ( f , wrt ( x , x ), x , y ); // evaluate the derivative d\u00b2u/dxdx double uxy = derivative ( f , wrt ( x , y ), x , y ); // evaluate the derivative d\u00b2u/dxdy double uyx = derivative ( f , wrt ( y , x ), x , y ); // evaluate the derivative d\u00b2u/dydx double uyy = derivative ( f , wrt ( y , y ), x , y ); // evaluate the derivative d\u00b2u/dydy cout << \"Allan\" << endl ; cout << \"u = \" << u << endl ; // print the evaluated output u cout << \"ux = \" << ux << endl ; // print the evaluated derivative du/dx cout << \"uy = \" << uy << endl ; // print the evaluated derivative du/dy cout << \"uxx = \" << uxx << endl ; // print the evaluated derivative d\u00b2u/dxdx cout << \"uxy = \" << uxy << endl ; // print the evaluated derivative d\u00b2u/dxdy cout << \"uyx = \" << uyx << endl ; // print the evaluated derivative d\u00b2u/dydx cout << \"uyy = \" << uyy << endl ; // print the evaluated derivative d\u00b2u/dydy } Reverse mode \u00b6 Single-variable function \u00b6 // C++ includes #include <iostream> using namespace std ; // autodiff include #include <autodiff/reverse.hpp> using namespace autodiff ; // The single-variable function for which derivatives are needed var f ( var x ) { return 1 + x + x * x + 1 / x + log ( x ); } int main () { var x = 2.0 ; // the input variable x var u = f ( x ); // the output variable u Derivatives dud = derivatives ( u ); // evaluate all derivatives of u var dudx = dud ( x ); // extract the derivative du/dx cout << \"u = \" << u << endl ; // print the evaluated output u cout << \"du/dx = \" << dudx << endl ; // print the evaluated derivative du/dx } Multi-variable function \u00b6 // C++ includes #include <iostream> using namespace std ; // autodiff include #include <autodiff/reverse.hpp> using namespace autodiff ; // The multi-variable function for which derivatives are needed var f ( var x , var y , var z ) { return 1 + x + y + z + x * y + y * z + x * z + x * y * z + exp ( x / y + y / z ); } int main () { var x = 1.0 ; // the input variable x var y = 2.0 ; // the input variable y var z = 3.0 ; // the input variable z var u = f ( x , y , z ); // the output variable u Derivatives dud = derivatives ( u ); // evaluate all derivatives of u var dudx = dud ( x ); // extract the derivative du/dx var dudy = dud ( y ); // extract the derivative du/dy var dudz = dud ( z ); // extract the derivative du/dz cout << \"u = \" << u << endl ; // print the evaluated output u cout << \"du/dx = \" << dudx << endl ; // print the evaluated derivative du/dx cout << \"du/dy = \" << dudy << endl ; // print the evaluated derivative du/dy cout << \"du/dz = \" << dudz << endl ; // print the evaluated derivative du/dz } Multi-variable function with parameters \u00b6 // C++ includes #include <iostream> using namespace std ; // autodiff include #include <autodiff/reverse.hpp> using namespace autodiff ; // A type defining parameters for a function of interest struct Params { var a ; var b ; var c ; }; // The function that depends on parameters for which derivatives are needed var f ( var x , const Params & params ) { return params . a * sin ( x ) + params . b * cos ( x ) + params . c * sin ( x ) * cos ( x ); } int main () { Params params ; // initialize the parameter variables params . a = 1.0 ; // the parameter a of type var, not double! params . b = 2.0 ; // the parameter b of type var, not double! params . c = 3.0 ; // the parameter c of type var, not double! var x = 0.5 ; // the input variable x var u = f ( x , params ); // the output variable u Derivatives dud = derivatives ( u ); // evaluate all derivatives of u var dudx = dud ( x ); // extract the derivative du/dx var duda = dud ( params . a ); // extract the derivative du/da var dudb = dud ( params . b ); // extract the derivative du/db var dudc = dud ( params . c ); // extract the derivative du/dc cout << \"u = \" << u << endl ; // print the evaluated output u cout << \"du/dx = \" << dudx << endl ; // print the evaluated derivative du/dx cout << \"du/da = \" << duda << endl ; // print the evaluated derivative du/da cout << \"du/db = \" << dudb << endl ; // print the evaluated derivative du/db cout << \"du/dc = \" << dudc << endl ; // print the evaluated derivative du/dc } Gradient of a scalar function \u00b6 // C++ includes #include <iostream> using namespace std ; // Eigen includes #include <eigen3/Eigen/Core> using namespace Eigen ; // autodiff include #include <autodiff/reverse.hpp> #include <autodiff/reverse/eigen.hpp> using namespace autodiff ; // The scalar function for which the gradient is needed var f ( const VectorXvar & x ) { return sqrt ( x . cwiseProduct ( x ). sum ()); // sqrt(sum([x(i) * x(i) for i = 1:5])) } int main () { VectorXvar x ( 5 ); // the input vector x with 5 variables x << 1 , 2 , 3 , 4 , 5 ; // x = [1, 2, 3, 4, 5] var y = f ( x ); // the output variable y VectorXd dydx = gradient ( y , x ); // evaluate the gradient vector dy/dx cout << \"y = \" << y << endl ; // print the evaluated output y cout << \"dy/dx = \\n \" << dydx << endl ; // print the evaluated gradient vector dy/dx } Hessian of a scalar function \u00b6 // C++ includes #include <iostream> using namespace std ; // Eigen includes #include <eigen3/Eigen/Core> using namespace Eigen ; // autodiff include #include <autodiff/reverse.hpp> #include <autodiff/reverse/eigen.hpp> using namespace autodiff ; // The scalar function for which the gradient is needed var f ( const VectorXvar & x ) { return sqrt ( x . cwiseProduct ( x ). sum ()); // sqrt(sum([x(i) * x(i) for i = 1:5])) } int main () { VectorXvar x ( 5 ); // the input vector x with 5 variables x << 1 , 2 , 3 , 4 , 5 ; // x = [1, 2, 3, 4, 5] var u = f ( x ); // the output variable u MatrixXd dudx = hessian ( u , x ); // evaluate the Hessian matrix d2u/dx2 cout << \"u = \" << u << endl ; // print the evaluated output u cout << \"du/dx = \\n \" << dudx << endl ; // print the evaluated gradient vector du/dx } Higher-order derivatives of a single-variable function \u00b6 // C++ includes #include <iostream> using namespace std ; // autodiff include #include <autodiff/reverse.hpp> using namespace autodiff ; int main () { var x = 0.5 ; // the input variable x var u = sin ( x ) * cos ( x ); // the output variable u DerivativesX dud = derivativesx ( u ); // evaluate the first order derivatives of u var dudx = dud ( x ); // extract the first order derivative du/dx of type var, not double! DerivativesX d2udxd = derivativesx ( dudx ); // evaluate the second order derivatives of du/dx var d2udxdx = d2udxd ( x ); // extract the second order derivative d2u/dxdx of type var, not double! cout << \"u = \" << u << endl ; // print the evaluated output variable u cout << \"du/dx = \" << dudx << endl ; // print the evaluated first order derivative du/dx cout << \"d2u/dx2 = \" << d2udxdx << endl ; // print the evaluated second order derivative d2u/dxdx } Higher-order derivatives of a multi-variable function \u00b6 // C++ includes #include <iostream> using namespace std ; // autodiff include #include <autodiff/reverse.hpp> using namespace autodiff ; int main () { var x = 1.0 ; // the input variable x var y = 0.5 ; // the input variable y var z = 2.0 ; // the input variable z var u = x * log ( y ) * exp ( z ); // the output variable u DerivativesX dud = derivativesx ( u ); // evaluate all derivatives of u using autodiff::derivativesx! var dudx = dud ( x ); // extract the first order derivative du/dx of type var, not double! var dudy = dud ( y ); // extract the first order derivative du/dy of type var, not double! var dudz = dud ( z ); // extract the first order derivative du/dz of type var, not double! DerivativesX d2udxd = derivativesx ( dudx ); // evaluate all derivatives of dudx using autodiff::derivativesx! DerivativesX d2udyd = derivativesx ( dudy ); // evaluate all derivatives of dudy using autodiff::derivativesx! DerivativesX d2udzd = derivativesx ( dudz ); // evaluate all derivatives of dudz using autodiff::derivativesx! var d2udxdx = d2udxd ( x ); // extract the second order derivative d2u/dxdx of type var, not double! var d2udxdy = d2udxd ( y ); // extract the second order derivative d2u/dxdy of type var, not double! var d2udxdz = d2udxd ( z ); // extract the second order derivative d2u/dxdz of type var, not double! var d2udydx = d2udyd ( x ); // extract the second order derivative d2u/dydx of type var, not double! var d2udydy = d2udyd ( y ); // extract the second order derivative d2u/dydy of type var, not double! var d2udydz = d2udyd ( z ); // extract the second order derivative d2u/dydz of type var, not double! var d2udzdx = d2udzd ( x ); // extract the second order derivative d2u/dzdx of type var, not double! var d2udzdy = d2udzd ( y ); // extract the second order derivative d2u/dzdy of type var, not double! var d2udzdz = d2udzd ( z ); // extract the second order derivative d2u/dzdz of type var, not double! cout << \"u = \" << u << endl ; // print the evaluated output variable u cout << \"du/dx = \" << dudx << endl ; // print the evaluated first order derivative du/dx cout << \"du/dy = \" << dudy << endl ; // print the evaluated first order derivative du/dy cout << \"du/dz = \" << dudz << endl ; // print the evaluated first order derivative du/dz cout << \"d2udxdx = \" << d2udxdx << endl ; // print the evaluated second order derivative d2u/dxdx cout << \"d2udxdy = \" << d2udxdy << endl ; // print the evaluated second order derivative d2u/dxdy cout << \"d2udxdz = \" << d2udxdz << endl ; // print the evaluated second order derivative d2u/dxdz cout << \"d2udydx = \" << d2udydx << endl ; // print the evaluated second order derivative d2u/dydx cout << \"d2udydy = \" << d2udydy << endl ; // print the evaluated second order derivative d2u/dydy cout << \"d2udydz = \" << d2udydz << endl ; // print the evaluated second order derivative d2u/dydz cout << \"d2udzdx = \" << d2udzdx << endl ; // print the evaluated second order derivative d2u/dzdx cout << \"d2udzdy = \" << d2udzdy << endl ; // print the evaluated second order derivative d2u/dzdy cout << \"d2udzdz = \" << d2udzdz << endl ; // print the evaluated second order derivative d2u/dzdz } Integration with CMake-based projects \u00b6 Integrating autodiff in a CMake-based project is very simple as shown next. Let's assume our CMake-based project consists of two files: main.cpp and CMakeLists.txt , whose contents are shown below: main.cpp #include <iostream> using namespace std ; #include <autodiff/forward.hpp> using namespace autodiff ; dual f ( dual x ) { return 1 + x + x * x + 1 / x + log ( x ); } int main () { dual x = 1.0 ; dual u = f ( x ); double dudx = derivative ( f , wrt ( x ), x ); cout << \"u = \" << u << endl ; cout << \"du/dx = \" << dudx << endl ; } CMakeLists.txt cmake_minimum_required ( VERSION 3.0 ) project ( app ) find_package ( autodiff ) add_executable ( app main.cpp ) target_link_libraries ( app autodiff::autodiff ) In the CMakeLists.txt file, note the use of the command: find_package ( autodiff ) to find the header files of the autodiff library, and the command: target_link_libraries ( app autodiff::autodiff ) to link the executable target app against the autodiff library ( autodiff::autodiff ) using CMake's modern target-based design. To build the application, do: mkdir build && cd build cmake .. -DCMAKE_PREFIX_PATH = /path/to/autodiff/install/dir make Attention If autodiff has been installed system-wide, then the CMake argument CMAKE_PREFIX_PATH should not be needed. Otherwise, you will need to specify where autodiff is installed in your machine. For example: cmake .. -DCMAKE_PREFIX_PATH = $HOME /local assuming directory $HOME/local is where autodiff was installed to, which should then contain the following directory: $HOME/local/include/autodiff/ where the autodiff header files are located. To execute the application, do: ./app","title":"Tutorials"},{"location":"tutorials/#tutorials","text":"","title":"Tutorials"},{"location":"tutorials/#forward-mode","text":"","title":"Forward mode"},{"location":"tutorials/#single-variable-function","text":"// C++ includes #include <iostream> using namespace std ; // autodiff include #include <autodiff/forward.hpp> using namespace autodiff ; // The single-variable function for which derivatives are needed dual f ( dual x ) { return 1 + x + x * x + 1 / x + log ( x ); } int main () { dual x = 2.0 ; // the input variable x dual u = f ( x ); // the output variable u double dudx = derivative ( f , wrt ( x ), x ); // evaluate the derivative du/dx cout << \"u = \" << u << endl ; // print the evaluated output u cout << \"du/dx = \" << dudx << endl ; // print the evaluated derivative du/dx }","title":"Single-variable function"},{"location":"tutorials/#multi-variable-function","text":"// C++ includes #include <iostream> using namespace std ; // autodiff include #include <autodiff/forward.hpp> using namespace autodiff ; // The multi-variable function for which derivatives are needed dual f ( dual x , dual y , dual z ) { return 1 + x + y + z + x * y + y * z + x * z + x * y * z + exp ( x / y + y / z ); } int main () { dual x = 1.0 ; // the input variable x dual y = 2.0 ; // the input variable y dual z = 3.0 ; // the input variable z dual u = f ( x , y , z ); // the output variable u double dudx = derivative ( f , wrt ( x ), x , y , z ); // evaluate the derivative du/dx double dudy = derivative ( f , wrt ( y ), x , y , z ); // evaluate the derivative du/dy double dudz = derivative ( f , wrt ( z ), x , y , z ); // evaluate the derivative du/dz cout << \"u = \" << u << endl ; // print the evaluated output u cout << \"du/dx = \" << dudx << endl ; // print the evaluated derivative du/dx cout << \"du/dy = \" << dudy << endl ; // print the evaluated derivative du/dy cout << \"du/dz = \" << dudz << endl ; // print the evaluated derivative du/dz }","title":"Multi-variable function"},{"location":"tutorials/#multi-variable-function-with-parameters","text":"// C++ includes #include <iostream> using namespace std ; // autodiff include #include <autodiff/forward.hpp> using namespace autodiff ; // A type defining parameters for a function of interest struct Params { dual a ; dual b ; dual c ; }; // The function that depends on parameters for which derivatives are needed dual f ( dual x , const Params & params ) { return params . a * sin ( x ) + params . b * cos ( x ) + params . c * sin ( x ) * cos ( x ); } int main () { Params params ; // initialize the parameter variables params . a = 1.0 ; // the parameter a of type dual, not double! params . b = 2.0 ; // the parameter b of type dual, not double! params . c = 3.0 ; // the parameter c of type dual, not double! dual x = 0.5 ; // the input variable x dual u = f ( x , params ); // the output variable u double dudx = derivative ( f , wrt ( x ), x , params ); // evaluate the derivative du/dx double duda = derivative ( f , wrt ( params . a ), x , params ); // evaluate the derivative du/da double dudb = derivative ( f , wrt ( params . b ), x , params ); // evaluate the derivative du/db double dudc = derivative ( f , wrt ( params . c ), x , params ); // evaluate the derivative du/dc cout << \"u = \" << u << endl ; // print the evaluated output u cout << \"du/dx = \" << dudx << endl ; // print the evaluated derivative du/dx cout << \"du/da = \" << duda << endl ; // print the evaluated derivative du/da cout << \"du/db = \" << dudb << endl ; // print the evaluated derivative du/db cout << \"du/dc = \" << dudc << endl ; // print the evaluated derivative du/dc }","title":"Multi-variable function with parameters"},{"location":"tutorials/#gradient-of-a-scalar-function","text":"// C++ includes #include <iostream> using namespace std ; // Eigen includes #include <eigen3/Eigen/Core> using namespace Eigen ; // autodiff include #include <autodiff/forward.hpp> #include <autodiff/forward/eigen.hpp> using namespace autodiff ; // The scalar function for which the gradient is needed dual f ( const VectorXdual & x ) { return x . cwiseProduct ( x ). sum (); // sum([x(i) * x(i) for i = 1:5]) } int main () { VectorXdual x ( 5 ); // the input vector x with 5 variables x << 1 , 2 , 3 , 4 , 5 ; // x = [1, 2, 3, 4, 5] dual u = f ( x ); // the output variable u VectorXd dudx = gradient ( f , x ); // evaluate the gradient vector du/dx cout << \"u = \" << u << endl ; // print the evaluated output u cout << \"grad(u) = \\n \" << dudx << endl ; // print the evaluated gradient vector du/dx }","title":"Gradient of a scalar function"},{"location":"tutorials/#jacobian-of-a-vector-function","text":"// C++ includes #include <iostream> using namespace std ; // Eigen includes #include <eigen3/Eigen/Core> using namespace Eigen ; // autodiff include #include <autodiff/forward.hpp> #include <autodiff/forward/eigen.hpp> using namespace autodiff ; // The vector function for which the Jacobian is needed VectorXdual f ( const VectorXdual & x ) { return x * x . sum (); } int main () { VectorXdual x ( 5 ); // the input vector x with 5 variables x << 1 , 2 , 3 , 4 , 5 ; // x = [1, 2, 3, 4, 5] VectorXdual u = f ( x ); // the output vector u MatrixXd dudx = jacobian ( f , u , x ); // evaluate the Jacobian matrix du/dx cout << \"u = \\n \" << u << endl ; // print the evaluated output vector u cout << \"du/dx = \\n \" << dudx << endl ; // print the evaluated Jacobian matrix du/dx }","title":"Jacobian of a vector function"},{"location":"tutorials/#higher-order-derivatives-of-a-multi-variable-function","text":"// C++ includes #include <iostream> using namespace std ; // autodiff include #include <autodiff/forward.hpp> using namespace autodiff ; // Define a 2nd order dual type using HigherOrderDual<N> construct. using dual2nd = HigherOrderDual < 2 > ; // The single-variable function for which derivatives are needed dual2nd f ( dual2nd x , dual2nd y ) { return 1 + x + y + x * y + y / x + log ( x / y ); } int main () { dual2nd x = 2.0 ; // the input variable x dual2nd y = 1.0 ; // the input variable y dual2nd u = f ( x , y ); // the output variable u dual ux = derivative ( f , wrt ( x ), x , y ); // evaluate the derivative du/dx dual uy = derivative ( f , wrt ( y ), x , y ); // evaluate the derivative du/dy double uxx = derivative ( f , wrt ( x , x ), x , y ); // evaluate the derivative d\u00b2u/dxdx double uxy = derivative ( f , wrt ( x , y ), x , y ); // evaluate the derivative d\u00b2u/dxdy double uyx = derivative ( f , wrt ( y , x ), x , y ); // evaluate the derivative d\u00b2u/dydx double uyy = derivative ( f , wrt ( y , y ), x , y ); // evaluate the derivative d\u00b2u/dydy cout << \"Allan\" << endl ; cout << \"u = \" << u << endl ; // print the evaluated output u cout << \"ux = \" << ux << endl ; // print the evaluated derivative du/dx cout << \"uy = \" << uy << endl ; // print the evaluated derivative du/dy cout << \"uxx = \" << uxx << endl ; // print the evaluated derivative d\u00b2u/dxdx cout << \"uxy = \" << uxy << endl ; // print the evaluated derivative d\u00b2u/dxdy cout << \"uyx = \" << uyx << endl ; // print the evaluated derivative d\u00b2u/dydx cout << \"uyy = \" << uyy << endl ; // print the evaluated derivative d\u00b2u/dydy }","title":"Higher-order derivatives of a multi-variable function"},{"location":"tutorials/#reverse-mode","text":"","title":"Reverse mode"},{"location":"tutorials/#single-variable-function_1","text":"// C++ includes #include <iostream> using namespace std ; // autodiff include #include <autodiff/reverse.hpp> using namespace autodiff ; // The single-variable function for which derivatives are needed var f ( var x ) { return 1 + x + x * x + 1 / x + log ( x ); } int main () { var x = 2.0 ; // the input variable x var u = f ( x ); // the output variable u Derivatives dud = derivatives ( u ); // evaluate all derivatives of u var dudx = dud ( x ); // extract the derivative du/dx cout << \"u = \" << u << endl ; // print the evaluated output u cout << \"du/dx = \" << dudx << endl ; // print the evaluated derivative du/dx }","title":"Single-variable function"},{"location":"tutorials/#multi-variable-function_1","text":"// C++ includes #include <iostream> using namespace std ; // autodiff include #include <autodiff/reverse.hpp> using namespace autodiff ; // The multi-variable function for which derivatives are needed var f ( var x , var y , var z ) { return 1 + x + y + z + x * y + y * z + x * z + x * y * z + exp ( x / y + y / z ); } int main () { var x = 1.0 ; // the input variable x var y = 2.0 ; // the input variable y var z = 3.0 ; // the input variable z var u = f ( x , y , z ); // the output variable u Derivatives dud = derivatives ( u ); // evaluate all derivatives of u var dudx = dud ( x ); // extract the derivative du/dx var dudy = dud ( y ); // extract the derivative du/dy var dudz = dud ( z ); // extract the derivative du/dz cout << \"u = \" << u << endl ; // print the evaluated output u cout << \"du/dx = \" << dudx << endl ; // print the evaluated derivative du/dx cout << \"du/dy = \" << dudy << endl ; // print the evaluated derivative du/dy cout << \"du/dz = \" << dudz << endl ; // print the evaluated derivative du/dz }","title":"Multi-variable function"},{"location":"tutorials/#multi-variable-function-with-parameters_1","text":"// C++ includes #include <iostream> using namespace std ; // autodiff include #include <autodiff/reverse.hpp> using namespace autodiff ; // A type defining parameters for a function of interest struct Params { var a ; var b ; var c ; }; // The function that depends on parameters for which derivatives are needed var f ( var x , const Params & params ) { return params . a * sin ( x ) + params . b * cos ( x ) + params . c * sin ( x ) * cos ( x ); } int main () { Params params ; // initialize the parameter variables params . a = 1.0 ; // the parameter a of type var, not double! params . b = 2.0 ; // the parameter b of type var, not double! params . c = 3.0 ; // the parameter c of type var, not double! var x = 0.5 ; // the input variable x var u = f ( x , params ); // the output variable u Derivatives dud = derivatives ( u ); // evaluate all derivatives of u var dudx = dud ( x ); // extract the derivative du/dx var duda = dud ( params . a ); // extract the derivative du/da var dudb = dud ( params . b ); // extract the derivative du/db var dudc = dud ( params . c ); // extract the derivative du/dc cout << \"u = \" << u << endl ; // print the evaluated output u cout << \"du/dx = \" << dudx << endl ; // print the evaluated derivative du/dx cout << \"du/da = \" << duda << endl ; // print the evaluated derivative du/da cout << \"du/db = \" << dudb << endl ; // print the evaluated derivative du/db cout << \"du/dc = \" << dudc << endl ; // print the evaluated derivative du/dc }","title":"Multi-variable function with parameters"},{"location":"tutorials/#gradient-of-a-scalar-function_1","text":"// C++ includes #include <iostream> using namespace std ; // Eigen includes #include <eigen3/Eigen/Core> using namespace Eigen ; // autodiff include #include <autodiff/reverse.hpp> #include <autodiff/reverse/eigen.hpp> using namespace autodiff ; // The scalar function for which the gradient is needed var f ( const VectorXvar & x ) { return sqrt ( x . cwiseProduct ( x ). sum ()); // sqrt(sum([x(i) * x(i) for i = 1:5])) } int main () { VectorXvar x ( 5 ); // the input vector x with 5 variables x << 1 , 2 , 3 , 4 , 5 ; // x = [1, 2, 3, 4, 5] var y = f ( x ); // the output variable y VectorXd dydx = gradient ( y , x ); // evaluate the gradient vector dy/dx cout << \"y = \" << y << endl ; // print the evaluated output y cout << \"dy/dx = \\n \" << dydx << endl ; // print the evaluated gradient vector dy/dx }","title":"Gradient of a scalar function"},{"location":"tutorials/#hessian-of-a-scalar-function","text":"// C++ includes #include <iostream> using namespace std ; // Eigen includes #include <eigen3/Eigen/Core> using namespace Eigen ; // autodiff include #include <autodiff/reverse.hpp> #include <autodiff/reverse/eigen.hpp> using namespace autodiff ; // The scalar function for which the gradient is needed var f ( const VectorXvar & x ) { return sqrt ( x . cwiseProduct ( x ). sum ()); // sqrt(sum([x(i) * x(i) for i = 1:5])) } int main () { VectorXvar x ( 5 ); // the input vector x with 5 variables x << 1 , 2 , 3 , 4 , 5 ; // x = [1, 2, 3, 4, 5] var u = f ( x ); // the output variable u MatrixXd dudx = hessian ( u , x ); // evaluate the Hessian matrix d2u/dx2 cout << \"u = \" << u << endl ; // print the evaluated output u cout << \"du/dx = \\n \" << dudx << endl ; // print the evaluated gradient vector du/dx }","title":"Hessian of a scalar function"},{"location":"tutorials/#higher-order-derivatives-of-a-single-variable-function","text":"// C++ includes #include <iostream> using namespace std ; // autodiff include #include <autodiff/reverse.hpp> using namespace autodiff ; int main () { var x = 0.5 ; // the input variable x var u = sin ( x ) * cos ( x ); // the output variable u DerivativesX dud = derivativesx ( u ); // evaluate the first order derivatives of u var dudx = dud ( x ); // extract the first order derivative du/dx of type var, not double! DerivativesX d2udxd = derivativesx ( dudx ); // evaluate the second order derivatives of du/dx var d2udxdx = d2udxd ( x ); // extract the second order derivative d2u/dxdx of type var, not double! cout << \"u = \" << u << endl ; // print the evaluated output variable u cout << \"du/dx = \" << dudx << endl ; // print the evaluated first order derivative du/dx cout << \"d2u/dx2 = \" << d2udxdx << endl ; // print the evaluated second order derivative d2u/dxdx }","title":"Higher-order derivatives of a single-variable function"},{"location":"tutorials/#higher-order-derivatives-of-a-multi-variable-function_1","text":"// C++ includes #include <iostream> using namespace std ; // autodiff include #include <autodiff/reverse.hpp> using namespace autodiff ; int main () { var x = 1.0 ; // the input variable x var y = 0.5 ; // the input variable y var z = 2.0 ; // the input variable z var u = x * log ( y ) * exp ( z ); // the output variable u DerivativesX dud = derivativesx ( u ); // evaluate all derivatives of u using autodiff::derivativesx! var dudx = dud ( x ); // extract the first order derivative du/dx of type var, not double! var dudy = dud ( y ); // extract the first order derivative du/dy of type var, not double! var dudz = dud ( z ); // extract the first order derivative du/dz of type var, not double! DerivativesX d2udxd = derivativesx ( dudx ); // evaluate all derivatives of dudx using autodiff::derivativesx! DerivativesX d2udyd = derivativesx ( dudy ); // evaluate all derivatives of dudy using autodiff::derivativesx! DerivativesX d2udzd = derivativesx ( dudz ); // evaluate all derivatives of dudz using autodiff::derivativesx! var d2udxdx = d2udxd ( x ); // extract the second order derivative d2u/dxdx of type var, not double! var d2udxdy = d2udxd ( y ); // extract the second order derivative d2u/dxdy of type var, not double! var d2udxdz = d2udxd ( z ); // extract the second order derivative d2u/dxdz of type var, not double! var d2udydx = d2udyd ( x ); // extract the second order derivative d2u/dydx of type var, not double! var d2udydy = d2udyd ( y ); // extract the second order derivative d2u/dydy of type var, not double! var d2udydz = d2udyd ( z ); // extract the second order derivative d2u/dydz of type var, not double! var d2udzdx = d2udzd ( x ); // extract the second order derivative d2u/dzdx of type var, not double! var d2udzdy = d2udzd ( y ); // extract the second order derivative d2u/dzdy of type var, not double! var d2udzdz = d2udzd ( z ); // extract the second order derivative d2u/dzdz of type var, not double! cout << \"u = \" << u << endl ; // print the evaluated output variable u cout << \"du/dx = \" << dudx << endl ; // print the evaluated first order derivative du/dx cout << \"du/dy = \" << dudy << endl ; // print the evaluated first order derivative du/dy cout << \"du/dz = \" << dudz << endl ; // print the evaluated first order derivative du/dz cout << \"d2udxdx = \" << d2udxdx << endl ; // print the evaluated second order derivative d2u/dxdx cout << \"d2udxdy = \" << d2udxdy << endl ; // print the evaluated second order derivative d2u/dxdy cout << \"d2udxdz = \" << d2udxdz << endl ; // print the evaluated second order derivative d2u/dxdz cout << \"d2udydx = \" << d2udydx << endl ; // print the evaluated second order derivative d2u/dydx cout << \"d2udydy = \" << d2udydy << endl ; // print the evaluated second order derivative d2u/dydy cout << \"d2udydz = \" << d2udydz << endl ; // print the evaluated second order derivative d2u/dydz cout << \"d2udzdx = \" << d2udzdx << endl ; // print the evaluated second order derivative d2u/dzdx cout << \"d2udzdy = \" << d2udzdy << endl ; // print the evaluated second order derivative d2u/dzdy cout << \"d2udzdz = \" << d2udzdz << endl ; // print the evaluated second order derivative d2u/dzdz }","title":"Higher-order derivatives of a multi-variable function"},{"location":"tutorials/#integration-with-cmake-based-projects","text":"Integrating autodiff in a CMake-based project is very simple as shown next. Let's assume our CMake-based project consists of two files: main.cpp and CMakeLists.txt , whose contents are shown below: main.cpp #include <iostream> using namespace std ; #include <autodiff/forward.hpp> using namespace autodiff ; dual f ( dual x ) { return 1 + x + x * x + 1 / x + log ( x ); } int main () { dual x = 1.0 ; dual u = f ( x ); double dudx = derivative ( f , wrt ( x ), x ); cout << \"u = \" << u << endl ; cout << \"du/dx = \" << dudx << endl ; } CMakeLists.txt cmake_minimum_required ( VERSION 3.0 ) project ( app ) find_package ( autodiff ) add_executable ( app main.cpp ) target_link_libraries ( app autodiff::autodiff ) In the CMakeLists.txt file, note the use of the command: find_package ( autodiff ) to find the header files of the autodiff library, and the command: target_link_libraries ( app autodiff::autodiff ) to link the executable target app against the autodiff library ( autodiff::autodiff ) using CMake's modern target-based design. To build the application, do: mkdir build && cd build cmake .. -DCMAKE_PREFIX_PATH = /path/to/autodiff/install/dir make Attention If autodiff has been installed system-wide, then the CMake argument CMAKE_PREFIX_PATH should not be needed. Otherwise, you will need to specify where autodiff is installed in your machine. For example: cmake .. -DCMAKE_PREFIX_PATH = $HOME /local assuming directory $HOME/local is where autodiff was installed to, which should then contain the following directory: $HOME/local/include/autodiff/ where the autodiff header files are located. To execute the application, do: ./app","title":"Integration with CMake-based projects"}]}